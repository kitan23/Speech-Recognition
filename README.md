# Emotive   
### Emotion Recognition in Speech   
#### Sike Ogieva, Kien Tran, Bach Le and Suaryanshu Khanal

The aim of this project is to build and train neural networks to recognise the emotion in human speech. 

#### Data
We will be using the audio-speech subset of the Ryaerson Audio-Visual Database of Emotional Speech and Song. The dataset comprises WAVfiles, with each one of 24 actors contributing 60 recordings, totaling 1,440 files. There are equal numbers of male and and female actors (12 each). The men are assigned odd number actor ids and the women even numbers. 
Every actor delivers their lines in a level North American accent. Files are identified by emotion (neutral, calm, happy, sad, angry, fearful, disgusted and surprised); emotional intensity (normal and strong), the text of their statement, and the speaking actor. Neutral emotions have no intensity.




