{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a29fc52-3059-426a-861d-c030c5b4228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6997c13c-074f-47eb-8cef-cd1166d3e174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 18:28:33.333283: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-20 18:28:33.359623: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-20 18:28:33.359650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-20 18:28:33.360222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-20 18:28:33.364361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from audiomentations import AddGaussianNoise, Compose, PitchShift, Shift, TimeStretch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5245ac-9c41-422b-b11c-a934ce72b5bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "emotion_list = {\n",
    "    0: \"neutral\",\n",
    "    1: \"calm\",\n",
    "    2: \"happy\",\n",
    "    3: \"sad\",\n",
    "    4: \"angry\",\n",
    "    5: \"fearful\",\n",
    "    6: \"disgusted\",\n",
    "    7: \"surprised\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405f4a50-fa52-4dd8-9dc3-63b22fe2d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.002, p=0.5),  # p = 0.5\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Shift(p=0.5),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84ae76d-ccf8-409c-bcab-0e55dd24092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path, emotion_list):\n",
    "    fileName = os.path.basename(path)\n",
    "    parts = fileName.split(\".\")[0].split(\"-\")\n",
    "    return int(parts[2]) - 1\n",
    "\n",
    "\n",
    "def process_test_audios(paths):\n",
    "    batch_features, batch_labels = [], []\n",
    "    for path in paths:\n",
    "        audio, sample_rate = librosa.load(path)\n",
    "        batch_features.append(audio)\n",
    "        batch_labels.append(get_label(path, emotion_list))\n",
    "    return batch_features, batch_labels\n",
    "\n",
    "\n",
    "def audio_generator(file_paths, batch_size):\n",
    "    while True:\n",
    "        batch_paths = np.random.choice(a=file_paths, size=batch_size)\n",
    "        batch_features, batch_labels = [], []\n",
    "\n",
    "        for path in batch_paths:\n",
    "            audio, sample_rate = librosa.load(path)\n",
    "            augmented_audio = augment(samples=audio, sample_rate=sample_rate)\n",
    "            batch_features.append(augmented_audio)\n",
    "            # batch_features.append(audio)\n",
    "            batch_labels.append(get_label(path, emotion_list))\n",
    "\n",
    "        yield batch_features, batch_labels\n",
    "\n",
    "\n",
    "def extract_mfcc(audio):\n",
    "    return np.mean(librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=40).T, axis=0)\n",
    "\n",
    "def extract_chroma(audio):\n",
    "    return librosa.feature.chroma_stft(y=audio, sr=22050, hop_length=len(audio) // 39)\n",
    "\n",
    "def join_mfcc_chroma(audio):\n",
    "    mfcc = extract_mfcc(audio)\n",
    "    chroma = extract_chroma(audio)\n",
    "    \n",
    "    mfcc_t = mfcc.reshape((mfcc.shape[0],1)).T\n",
    "    \n",
    "    return np.concatenate((mfcc_t, chroma), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f823f0-e50b-4317-8748-f1fb508a33a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RAV = \"data/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "# dir_list = os.listdir(RAV)\n",
    "# paths = []\n",
    "# for dir in dir_list:\n",
    "#     files = os.listdir(RAV + dir)\n",
    "#     for file in files:\n",
    "#         paths.append(RAV + dir + \"/\" + file)\n",
    "\n",
    "# path_train, path_test = train_test_split(paths, test_size=0.2)\n",
    "\n",
    "# X_test, Y_test = process_test_audios(path_test)\n",
    "\n",
    "# batch_size = 24\n",
    "# gen = audio_generator(file_paths=path_train, batch_size=batch_size)\n",
    "# X_train, Y_train = [], []\n",
    "# for i in range(500):\n",
    "#     batch_data, batch_labels = next(gen)\n",
    "#     X_train += batch_data\n",
    "#     Y_train += batch_labels\n",
    "\n",
    "\n",
    "# Y_train, Y_test = to_categorical(Y_train), to_categorical(Y_test)\n",
    "# len(X_train), len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db758b5-c855-4964-bd45-20b29352cdb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data = {\"X_train_raw\": X_train, \"X_test_raw\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
    "# with open(\"./data/raw_data.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a183c8-fa07-42d3-aafa-69d5cea997ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio, sample_rate = librosa.load('../../data/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')\n",
    "# chroma = extract_chroma(audio)\n",
    "# mfcc = extract_mfcc(audio)\n",
    "# mfcc_t = mfcc.reshape((mfcc.shape[0],1)).T\n",
    "# mfcc_t.shape, chroma.shape\n",
    "# np.concatenate((mfcc_t, chroma), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f036b7bb-447b-4fa7-b85c-59748b16e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/raw_data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "X_train = data[\"X_train_raw\"]\n",
    "X_test = data[\"X_test_raw\"]\n",
    "Y_train = data[\"Y_train\"]\n",
    "Y_test = data[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627cdb8e-99be-4f5e-9ed4-0f5f4d497514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([join_mfcc_chroma(audio) for audio in X_train])\n",
    "X_test = np.array([join_mfcc_chroma(audio) for audio in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d0a0de-e83b-4954-896c-562ab37d759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"X_train\": X_train, \"X_test\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
    "with open(\"./data/exp_w_aug_chroma_processed_data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aec06d3-0f28-4875-a67f-5b680b1d953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array([extract_mfcc(audio) for audio in X_train])\n",
    "# X_test = np.array([extract_mfcc(audio) for audio in X_test])\n",
    "# X_train = np.expand_dims(X_train, -1)\n",
    "# X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0316b99f-0705-4b35-846d-1b5b8fc9ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\"X_train\": X_train, \"X_test\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
    "# with open(\"./data/processed_data.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e01688-5dbb-4fb7-b0cc-d8086eec9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/processed_data.pickle\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "# X_train = data[\"X_train\"]\n",
    "# X_test = data[\"X_test\"]\n",
    "# Y_train = data[\"Y_train\"]\n",
    "# Y_test = data[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edd9825-4b5b-496b-8bc0-056dc53b8e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 13, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba6a34-6cb4-4e58-852d-154dd65dcae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
