{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a29fc52-3059-426a-861d-c030c5b4228b",
      "metadata": {
        "id": "9a29fc52-3059-426a-861d-c030c5b4228b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6997c13c-074f-47eb-8cef-cd1166d3e174",
      "metadata": {
        "scrolled": true,
        "id": "6997c13c-074f-47eb-8cef-cd1166d3e174",
        "outputId": "8f3c2309-87a5-4845-c0e3-f037a3fe190a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'audiomentations'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-668b99fe36eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maudiomentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddGaussianNoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPitchShift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeStretch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'audiomentations'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import gc\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from audiomentations import AddGaussianNoise, Compose, PitchShift, Shift, TimeStretch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5245ac-9c41-422b-b11c-a934ce72b5bf",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "0d5245ac-9c41-422b-b11c-a934ce72b5bf"
      },
      "outputs": [],
      "source": [
        "emotion_list = {\n",
        "    0: \"neutral\",\n",
        "    1: \"calm\",\n",
        "    2: \"happy\",\n",
        "    3: \"sad\",\n",
        "    4: \"angry\",\n",
        "    5: \"fearful\",\n",
        "    6: \"disgusted\",\n",
        "    7: \"surprised\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405f4a50-fa52-4dd8-9dc3-63b22fe2d0b5",
      "metadata": {
        "id": "405f4a50-fa52-4dd8-9dc3-63b22fe2d0b5"
      },
      "outputs": [],
      "source": [
        "augment = Compose(\n",
        "    [\n",
        "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.002, p=0.5),  # p = 0.5\n",
        "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "        Shift(p=0.5),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e84ae76d-ccf8-409c-bcab-0e55dd24092a",
      "metadata": {
        "id": "e84ae76d-ccf8-409c-bcab-0e55dd24092a"
      },
      "outputs": [],
      "source": [
        "def get_label(path, emotion_list):\n",
        "    fileName = os.path.basename(path)\n",
        "    parts = fileName.split(\".\")[0].split(\"-\")\n",
        "    return int(parts[2]) - 1\n",
        "\n",
        "\n",
        "def process_test_audios(paths):\n",
        "    batch_features, batch_labels = [], []\n",
        "    for path in paths:\n",
        "        audio, sample_rate = librosa.load(path)\n",
        "        batch_features.append(audio)\n",
        "        batch_labels.append(get_label(path, emotion_list))\n",
        "    return batch_features, batch_labels\n",
        "\n",
        "\n",
        "def audio_generator(file_paths, batch_size):\n",
        "    while True:\n",
        "        batch_paths = np.random.choice(a=file_paths, size=batch_size)\n",
        "        batch_features, batch_labels = [], []\n",
        "\n",
        "        for path in batch_paths:\n",
        "            audio, sample_rate = librosa.load(path)\n",
        "            augmented_audio = augment(samples=audio, sample_rate=sample_rate)\n",
        "            batch_features.append(augmented_audio)\n",
        "            # batch_features.append(audio)\n",
        "            batch_labels.append(get_label(path, emotion_list))\n",
        "\n",
        "        yield batch_features, batch_labels\n",
        "\n",
        "\n",
        "def extract_mfcc(audio):\n",
        "    return np.mean(librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=40).T, axis=0)\n",
        "\n",
        "def extract_chroma(audio):\n",
        "    return librosa.feature.chroma_stft(y=audio, sr=22050, hop_length=len(audio) // 39)\n",
        "\n",
        "def join_mfcc_chroma(audio):\n",
        "    mfcc = extract_mfcc(audio)\n",
        "    chroma = extract_chroma(audio)\n",
        "\n",
        "    mfcc_t = mfcc.reshape((mfcc.shape[0],1)).T\n",
        "\n",
        "    return np.concatenate((mfcc_t, chroma), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f823f0-e50b-4317-8748-f1fb508a33a9",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "e1f823f0-e50b-4317-8748-f1fb508a33a9"
      },
      "outputs": [],
      "source": [
        "# RAV = \"data/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
        "# dir_list = os.listdir(RAV)\n",
        "# paths = []\n",
        "# for dir in dir_list:\n",
        "#     files = os.listdir(RAV + dir)\n",
        "#     for file in files:\n",
        "#         paths.append(RAV + dir + \"/\" + file)\n",
        "\n",
        "# path_train, path_test = train_test_split(paths, test_size=0.2)\n",
        "\n",
        "# X_test, Y_test = process_test_audios(path_test)\n",
        "\n",
        "# batch_size = 24\n",
        "# gen = audio_generator(file_paths=path_train, batch_size=batch_size)\n",
        "# X_train, Y_train = [], []\n",
        "# for i in range(500):\n",
        "#     batch_data, batch_labels = next(gen)\n",
        "#     X_train += batch_data\n",
        "#     Y_train += batch_labels\n",
        "\n",
        "\n",
        "# Y_train, Y_test = to_categorical(Y_train), to_categorical(Y_test)\n",
        "# len(X_train), len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8db758b5-c855-4964-bd45-20b29352cdb0",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "8db758b5-c855-4964-bd45-20b29352cdb0"
      },
      "outputs": [],
      "source": [
        "# data = {\"X_train_raw\": X_train, \"X_test_raw\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
        "# with open(\"./data/raw_data.pickle\", \"wb\") as f:\n",
        "#     pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a183c8-fa07-42d3-aafa-69d5cea997ab",
      "metadata": {
        "id": "c9a183c8-fa07-42d3-aafa-69d5cea997ab"
      },
      "outputs": [],
      "source": [
        "# audio, sample_rate = librosa.load('../../data/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')\n",
        "# chroma = extract_chroma(audio)\n",
        "# mfcc = extract_mfcc(audio)\n",
        "# mfcc_t = mfcc.reshape((mfcc.shape[0],1)).T\n",
        "# mfcc_t.shape, chroma.shape\n",
        "# np.concatenate((mfcc_t, chroma), axis=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f036b7bb-447b-4fa7-b85c-59748b16e024",
      "metadata": {
        "id": "f036b7bb-447b-4fa7-b85c-59748b16e024"
      },
      "outputs": [],
      "source": [
        "with open(\"./data/raw_data.pickle\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "X_train = data[\"X_train_raw\"]\n",
        "X_test = data[\"X_test_raw\"]\n",
        "Y_train = data[\"Y_train\"]\n",
        "Y_test = data[\"Y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627cdb8e-99be-4f5e-9ed4-0f5f4d497514",
      "metadata": {
        "id": "627cdb8e-99be-4f5e-9ed4-0f5f4d497514"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([join_mfcc_chroma(audio) for audio in X_train])\n",
        "X_test = np.array([join_mfcc_chroma(audio) for audio in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d0a0de-e83b-4954-896c-562ab37d759a",
      "metadata": {
        "id": "d2d0a0de-e83b-4954-896c-562ab37d759a"
      },
      "outputs": [],
      "source": [
        "data = {\"X_train\": X_train, \"X_test\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
        "with open(\"./data/exp_w_aug_chroma_processed_data.pickle\", \"wb\") as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aec06d3-0f28-4875-a67f-5b680b1d953b",
      "metadata": {
        "id": "5aec06d3-0f28-4875-a67f-5b680b1d953b"
      },
      "outputs": [],
      "source": [
        "# X_train = np.array([extract_mfcc(audio) for audio in X_train])\n",
        "# X_test = np.array([extract_mfcc(audio) for audio in X_test])\n",
        "# X_train = np.expand_dims(X_train, -1)\n",
        "# X_test = np.expand_dims(X_test, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0316b99f-0705-4b35-846d-1b5b8fc9ef3c",
      "metadata": {
        "id": "0316b99f-0705-4b35-846d-1b5b8fc9ef3c"
      },
      "outputs": [],
      "source": [
        "# data = {\"X_train\": X_train, \"X_test\": X_test, \"Y_train\": Y_train, \"Y_test\": Y_test}\n",
        "# with open(\"./data/processed_data.pickle\", \"wb\") as f:\n",
        "#     pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e01688-5dbb-4fb7-b0cc-d8086eec9337",
      "metadata": {
        "id": "98e01688-5dbb-4fb7-b0cc-d8086eec9337"
      },
      "outputs": [],
      "source": [
        "# with open(\"./data/processed_data.pickle\", \"rb\") as f:\n",
        "#     data = pickle.load(f)\n",
        "# X_train = data[\"X_train\"]\n",
        "# X_test = data[\"X_test\"]\n",
        "# Y_train = data[\"Y_train\"]\n",
        "# Y_test = data[\"Y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edd9825-4b5b-496b-8bc0-056dc53b8e1c",
      "metadata": {
        "id": "6edd9825-4b5b-496b-8bc0-056dc53b8e1c",
        "outputId": "4bb863a0-5f92-447a-e726-3bea2ebca01a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 13, 40)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ba6a34-6cb4-4e58-852d-154dd65dcae9",
      "metadata": {
        "id": "a9ba6a34-6cb4-4e58-852d-154dd65dcae9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}